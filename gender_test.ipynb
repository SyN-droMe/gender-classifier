{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeqLC7syV50F",
        "outputId": "c915e956-7e11-4f43-cc8f-1f213e852967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.7)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQn0Q_cTWDRD",
        "outputId": "bf88d07f-825e-4e42-e8fb-84ab4648e72b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brG7o2r_VzC5"
      },
      "outputs": [],
      "source": [
        "import onnxruntime as ort"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "GB_qtFENV-vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import onnxruntime\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch"
      ],
      "metadata": {
        "id": "29eW5gjkXyk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1YOAlmQWMVX",
        "outputId": "048df441-859a-4ee6-ba8a-7d963d213af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = \"/content/gdrive/My Drive/test_images\"\n",
        "#image_dir = \"/content/gdrive/MyDrive/comp_test\""
      ],
      "metadata": {
        "id": "yKFa9d_ZXhx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"from scipy.special import softmax\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "sess = ort.InferenceSession(\"/content/gdrive/My Drive/first_trial.onnx\")   #[man, woman]\n",
        "#sess = ort.InferenceSession(\"/content/gdrive/MyDrive/components_new.onnx\")\n",
        "#image_dir = \"/content/gdrive/My Drive/test_images\"\n",
        "\n",
        "# Define the same transform as in your training code\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Iterate over images in directory\n",
        "for image_name in os.listdir(image_dir):\n",
        "    # Load image\n",
        "    img = cv2.imread(os.path.join(image_dir, image_name))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = Image.fromarray(img)\n",
        "    img = transform(img)\n",
        "\n",
        "    # Add batch dimension\n",
        "    img_batch = np.expand_dims(img, axis=0)\n",
        "\n",
        "    # Run the model (modify 'input_name' and 'output_name' accordingly)\n",
        "    input_name = sess.get_inputs()[0].name\n",
        "    output_name = sess.get_outputs()[0].name\n",
        "    result = sess.run([output_name], {input_name: img_batch})\n",
        "\n",
        "    # Apply softmax to convert logits to probabilities\n",
        "    proba = softmax(result[0], axis=1)\n",
        "\n",
        "    # Print result\n",
        "    print(f\"Result for {image_name}: {proba}\")  #[m,w]: m,m,m,w,m,m,m,w,m,m,m,m,w,m,w\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "0msvtac5vuD7",
        "outputId": "3a8de9e6-a533-4ee7-c93a-378ced608964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from scipy.special import softmax\\nimport torchvision.transforms as transforms\\nfrom PIL import Image\\n\\nsess = ort.InferenceSession(\"/content/gdrive/My Drive/first_trial.onnx\")   #[man, woman]\\n#sess = ort.InferenceSession(\"/content/gdrive/MyDrive/components_new.onnx\") \\n#image_dir = \"/content/gdrive/My Drive/test_images\"\\n\\n# Define the same transform as in your training code\\ntransform = transforms.Compose([\\n    transforms.Resize((224, 224)),\\n    transforms.ToTensor(),\\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\n\\n# Iterate over images in directory\\nfor image_name in os.listdir(image_dir):\\n    # Load image\\n    img = cv2.imread(os.path.join(image_dir, image_name))\\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\n    img = Image.fromarray(img)\\n    img = transform(img)\\n\\n    # Add batch dimension\\n    img_batch = np.expand_dims(img, axis=0)\\n\\n    # Run the model (modify \\'input_name\\' and \\'output_name\\' accordingly)\\n    input_name = sess.get_inputs()[0].name\\n    output_name = sess.get_outputs()[0].name\\n    result = sess.run([output_name], {input_name: img_batch})\\n\\n    # Apply softmax to convert logits to probabilities\\n    proba = softmax(result[0], axis=1)\\n\\n    # Print result\\n    print(f\"Result for {image_name}: {proba}\")  #[m,w]: m,m,m,w,m,m,m,w,m,m,m,m,w,m,w'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the ONNX model\n",
        "#onnx_model_path = '/content/gdrive/MyDrive/components_new.onnx'\n",
        "onnx_model_path ='/content/gdrive/My Drive/first_trial.onnx'\n",
        "sess = onnxruntime.InferenceSession(onnx_model_path)\n",
        "\n",
        "# Function to preprocess an image\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = image.resize((224, 224))\n",
        "    image = np.array(image).astype(np.float32) / 255.0\n",
        "    image = (image - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
        "    image = np.transpose(image, (2, 0, 1))\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    return image.astype(np.float32)  # Ensure float32 data type\n",
        "\n",
        "# Function to make predictions\n",
        "def predict_gender(image_path):\n",
        "    input_image = preprocess_image(image_path)\n",
        "    input_name = sess.get_inputs()[0].name\n",
        "    output_name = sess.get_outputs()[0].name\n",
        "\n",
        "    # Run the ONNX model\n",
        "    result = sess.run([output_name], {input_name: input_image})\n",
        "\n",
        "    # Apply sigmoid to convert logits to probabilities\n",
        "    probabilities = 1 / (1 + np.exp(-result[0]))\n",
        "\n",
        "    class_names = ['Male', 'Female']\n",
        "    #class_names = ['Resistor','Capacitor']\n",
        "    predicted_class = class_names[np.argmax(probabilities)]\n",
        "\n",
        "    return predicted_class, probabilities\n",
        "\n",
        "# Path to the folder containing images\n",
        "#image_folder_path = '/content/gdrive/MyDrive/comp_test'  # Specify the path to your test images\n",
        "image_dir = \"/content/gdrive/My Drive/test_images\"\n",
        "\n",
        "# Display predictions for each image in the folder\n",
        "for filename in os.listdir(image_folder_path):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        image_path = os.path.join(image_folder_path, filename)\n",
        "\n",
        "        # Make predictions\n",
        "        predicted_class, probabilities = predict_gender(image_path)\n",
        "        #predicted_class, probabilities = predict_component(image_path)\n",
        "\n",
        "        # Display the image and prediction\n",
        "        img = Image.open(image_path)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f'Prediction: {predicted_class} (Male: {float(probabilities[0][0]):.2f}, Female: {float(probabilities[0][1]):.2f})')\n",
        "        #plt.title(f'Prediction: {predicted_class} (Resistor: {float(probabilities[0][0]):.2f}, Capacitor: {float(probabilities[0][1]):.2f})')\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "2brYgrJxZXBd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}